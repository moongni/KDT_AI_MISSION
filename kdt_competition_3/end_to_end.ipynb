{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\moooo\\\\git\\\\KDT_AI_MISSION\\\\kdt_competition_3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# TRAIN SETTING\n",
    "IMG_SIZE = 416\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "SEED = 12341\n",
    "CLASS_INFO = {0: 'background', 1:'Buffalo', 2:'Elephant', 3:'Rhinoceros', 4:'Zebra'}\n",
    "CLASSES = CLASS_INFO.keys()\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "PATIENCE = 10\n",
    "CONFIDENCE = 0.8\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "VISUALIZE_EVALUATED_IMAGE = True\n",
    "VISUALIZE_LOSS_GRAPH = True\n",
    "\n",
    "MEAN = np.array([0.485, 0.456, 0.406])\n",
    "STD = np.array([0.299, 0.224, 0.225])\n",
    "\n",
    "# PATH SETTING\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_PATH = os.path.join(ROOT_DIR, 'data')\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TRAIN_DF_PATH = os.path.join(TRAIN_PATH, 'train_output.csv')\n",
    "\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test')\n",
    "TEST_DF_PATH = os.path.join(TEST_PATH, 'test_output.csv')\n",
    "\n",
    "OUTPUT_PATH = os.path.join(ROOT_DIR, 'result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import *\n",
    "\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "class TrainTransform:\n",
    "    def __init__(self):\n",
    "        self.transforms = A.Compose([\n",
    "                            A.OneOf([\n",
    "                                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, val_shift_limit=0.2, p=0.9),\n",
    "                                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.9)\n",
    "                            ],p=0.9),                      \n",
    "                            A.ToGray(p=0.05),\n",
    "                            A.HorizontalFlip(p=0.2), \n",
    "                            A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1),\n",
    "                            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.2),\n",
    "                            ToTensorV2(p=1.0)\n",
    "                        ], p=1.0, bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        return self.transforms(**kwargs)\n",
    "    \n",
    "\n",
    "class TestTransform:\n",
    "    def __init__(self):\n",
    "        self.transforms = A.Compose([\n",
    "                            A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
    "                            ToTensorV2(p=1.0)\n",
    "                          ], p=1.0, bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "    \n",
    "    def __call__(self, **kwargs):\n",
    "        return self.transforms(**kwargs)\n",
    "\n",
    "\n",
    "def set_seed():\n",
    "    \"\"\"\n",
    "    fix seed to control the random variable \n",
    "    \"\"\"\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    collate function for the ObjectDetectionDataSet.\n",
    "    Only used by the dataloader.\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from config import config\n",
    "\n",
    "\n",
    "class ObjDetectionDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        df: Optional[pd.DataFrame],\n",
    "        transform: Optional[nn.Module] = None,\n",
    "        train: bool = True\n",
    "    ) -> None:\n",
    "        if not os.path.isdir(root):\n",
    "            raise Exception(f\"Invalid root path: {root}\")\n",
    "        if df is not None:\n",
    "            df = self.preprocessing(df)\n",
    "\n",
    "        self.root = root\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.img_size = (3, IMG_SIZE, IMG_SIZE)\n",
    "        self.train = train\n",
    "\n",
    "    def preprocessing(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        new_data = {\n",
    "            'label_idx': [],\n",
    "            'x_center': [],\n",
    "            'y_center': [],\n",
    "            'w': [],\n",
    "            'h': []\n",
    "        }\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            label = df.iloc[i]['label']\n",
    "            # multi labels\n",
    "            if '\\n' in label:\n",
    "                label = label.split('\\n')\n",
    "            else:\n",
    "                label = [label]\n",
    "\n",
    "            label_idx = []\n",
    "            x_center = []\n",
    "            y_center = []\n",
    "            w = []\n",
    "            h = []\n",
    "            for l in label:\n",
    "                idx, x_c, y_c, width, height = l.split(' ')\n",
    "                label_idx.append(int(idx))\n",
    "                x_center.append(float(x_c))\n",
    "                y_center.append(float(y_c))\n",
    "                w.append(float(width))\n",
    "                h.append(float(height))\n",
    "\n",
    "            new_data['label_idx'].append(label_idx)\n",
    "            new_data['x_center'].append(x_center)\n",
    "            new_data['y_center'].append(y_center)\n",
    "            new_data['w'].append(w)\n",
    "            new_data['h'].append(h)\n",
    "\n",
    "        new_data = pd.DataFrame(new_data)\n",
    "        return pd.concat([df, new_data], axis=1)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # get image from filepath\n",
    "        data = self.df.iloc[idx]\n",
    "        file_name = data['filename']\n",
    "        img_path = os.path.join(self.root, str(file_name).zfill(4) + '.jpg')\n",
    "\n",
    "        # open Image\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        img_size = image.shape\n",
    "        print(img_size)\n",
    "        \n",
    "        # get labels\n",
    "        labels = np.array(data['label_idx']) + 1  # 0 index -> background\n",
    "        num_objs = len(labels)\n",
    "\n",
    "        # get bounding box\n",
    "        x_center = (np.array(data['x_center']).reshape(-1, 1) * self.img_size[2]).astype(np.int32)\n",
    "        y_center = (np.array(data['y_center']).reshape(-1, 1) * self.img_size[1]).astype(np.int32)\n",
    "        width = ((np.array(data['w']) * self.img_size[2]).reshape(-1, 1) // 2).astype(np.int32)\n",
    "        height = ((np.array(data['h']) * self.img_size[1]).reshape(-1, 1) // 2).astype(np.int32)\n",
    "\n",
    "        x_0 = x_center - width\n",
    "        x_1 = x_center + width\n",
    "        y_0 = y_center - height\n",
    "        y_1 = y_center + height\n",
    "        boxes = np.hstack((x_0, y_0, x_1, y_1))\n",
    "        boxes = np.where( boxes > 0, boxes, 0.)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': boxes,\n",
    "                'labels': labels\n",
    "            }\n",
    "            transformed = self.transform(**sample)\n",
    "            image = transformed['image']\n",
    "            boxes = np.array(transformed['bboxes'], dtype=np.float64)\n",
    "            labels = np.array(transformed['labels'], dtype=np.int64)\n",
    "        else:\n",
    "            image = np.asarray(image)\n",
    "            image = ToTensorV2(p=1.0)(image)\n",
    "        print(type(image))\n",
    "        print(type(boxes), boxes)\n",
    "        print(type(labels), labels)\n",
    "        # get boxes area\n",
    "        area = ((boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]))\n",
    "        \n",
    "        # get iscrowd - 여러 인스턴스가 있는지\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = torch.from_numpy(boxes).float()\n",
    "        target['labels'] = torch.from_numpy(labels).to(torch.int64)\n",
    "        target['image_id'] = torch.tensor([file_name])\n",
    "        target['area'] = torch.from_numpy(area).float()\n",
    "        target['iscrowd'] = iscrowd\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Seed: 12341\n",
      "Torch Device: cpu\n",
      "Load Dataset from \n",
      " c:\\Users\\moooo\\git\\KDT_AI_MISSION\\kdt_competition_3\\data\\train\\train_output.csv \n",
      " c:\\Users\\moooo\\git\\KDT_AI_MISSION\\kdt_competition_3\\data\\test\\test_output.csv\n",
      "(423, 640, 3)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'> [[187.85        72.77541371 407.55       359.94326241]]\n",
      "<class 'numpy.ndarray'> [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moooo\\anaconda3\\lib\\site-packages\\albumentations\\augmentations\\dropout\\cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2004\\1647242308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# fix seed\n",
    "set_seed()\n",
    "print(f\"Set Seed: {SEED}\")\n",
    "print(f\"Torch Device: {DEVICE}\")\n",
    "\n",
    "# Data 불러오기\n",
    "train_df = pd.read_csv(TRAIN_DF_PATH)\n",
    "test_df = pd.read_csv(TEST_DF_PATH)\n",
    "\n",
    "train_dset = ObjDetectionDataset(TRAIN_PATH, train_df, TrainTransform(), train=True)\n",
    "# test_dset = ObjDetectionDataset(TEST_PATH, test_df, TestTransform, train=False)\n",
    "print(f\"Load Dataset from \\n {TRAIN_DF_PATH} \\n {TEST_DF_PATH}\")\n",
    "# print(f\"Train data size: {len(train_dset)}, Test data size: {len(test_dset)}\")\n",
    "\n",
    "images, labels = next(iter(train_dset))\n",
    "plt.imshow(images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "# Model 불러오기\n",
    "model = fasterrcnn_resnet_50()\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# get the model params\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "# Train model\n",
    "best_model, train_loss_list, test_loss_list = train(model, optimizer, dataloaders, lr_scheduler)\n",
    "\n",
    "# Save best model\n",
    "make_dir(OUTPUT_PATH)\n",
    "torch.save(best_model, os.path.join(OUTPUT_PATH, 'best_detector.pth'))\n",
    "\n",
    "# Get metrics score from test_loader\n",
    "map_result = mean_average_precision(best_model, test_loader)\n",
    "\n",
    "print(f\"Train score metrix\")\n",
    "pprint(map_result)\n",
    "\n",
    "# Save metrics score\n",
    "with open(os.path.join(OUTPUT_PATH, 'metrics.txt'), 'w') as f:\n",
    "    f.write(json.dumps(map_result, indent='\\t'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
