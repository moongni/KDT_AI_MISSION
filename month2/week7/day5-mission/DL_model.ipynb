{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaN_ByG0mrQb"
      },
      "source": [
        "# Deep Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg0kBZogdLfw"
      },
      "source": [
        "## Load Data in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnvX81tLnNMY",
        "outputId": "f578bb01-962a-4ad8-8c0f-277ffe183e7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('./drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqKv1bYxnS46",
        "outputId": "d001a1af-f461-4a9a-94d5-840e9499adb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/KDT-MISSION/month2/delivery_raw.csv.zip\n",
            "  inflating: delivery_raw.csv        \n",
            "  inflating: __MACOSX/._delivery_raw.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/KDT-MISSION/month2/delivery_raw.csv.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwjRN6M-ek0k"
      },
      "source": [
        "## Seed Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDyhcIJWen9o",
        "outputId": "a1c54d5a-4d76-490d-8c82-19c3ee19f009"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "seed = 42\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.enabled = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE40mZl6dRGj"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Tn7VEmi_n7BX",
        "outputId": "25ea05e6-6918-4696-f3a0-28bd3c279fda"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-10d300b8-bd5e-4610-ad0d-4134214d2c90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>market_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>actual_delivery_time</th>\n",
              "      <th>store_id</th>\n",
              "      <th>store_primary_category</th>\n",
              "      <th>order_protocol</th>\n",
              "      <th>total_items</th>\n",
              "      <th>subtotal</th>\n",
              "      <th>num_distinct_items</th>\n",
              "      <th>min_item_price</th>\n",
              "      <th>max_item_price</th>\n",
              "      <th>total_onshift</th>\n",
              "      <th>total_busy</th>\n",
              "      <th>total_outstanding_orders</th>\n",
              "      <th>estimated_order_place_duration</th>\n",
              "      <th>estimated_store_to_consumer_driving_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2015-02-06 22:24:17</td>\n",
              "      <td>2015-02-06 23:27:16</td>\n",
              "      <td>1845</td>\n",
              "      <td>american</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3441</td>\n",
              "      <td>4</td>\n",
              "      <td>557</td>\n",
              "      <td>1239</td>\n",
              "      <td>33.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>446</td>\n",
              "      <td>861.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2015-02-10 21:49:25</td>\n",
              "      <td>2015-02-10 22:56:29</td>\n",
              "      <td>5477</td>\n",
              "      <td>mexican</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1900</td>\n",
              "      <td>1</td>\n",
              "      <td>1400</td>\n",
              "      <td>1400</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>446</td>\n",
              "      <td>690.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2015-01-22 20:39:28</td>\n",
              "      <td>2015-01-22 21:09:09</td>\n",
              "      <td>5477</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1900</td>\n",
              "      <td>1</td>\n",
              "      <td>1900</td>\n",
              "      <td>1900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>446</td>\n",
              "      <td>690.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2015-02-03 21:21:45</td>\n",
              "      <td>2015-02-03 22:13:00</td>\n",
              "      <td>5477</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6900</td>\n",
              "      <td>5</td>\n",
              "      <td>600</td>\n",
              "      <td>1800</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>446</td>\n",
              "      <td>289.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2015-02-15 02:40:36</td>\n",
              "      <td>2015-02-15 03:20:26</td>\n",
              "      <td>5477</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3900</td>\n",
              "      <td>3</td>\n",
              "      <td>1100</td>\n",
              "      <td>1600</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>446</td>\n",
              "      <td>650.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10d300b8-bd5e-4610-ad0d-4134214d2c90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10d300b8-bd5e-4610-ad0d-4134214d2c90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10d300b8-bd5e-4610-ad0d-4134214d2c90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   market_id           created_at actual_delivery_time  store_id  \\\n",
              "0        1.0  2015-02-06 22:24:17  2015-02-06 23:27:16      1845   \n",
              "1        2.0  2015-02-10 21:49:25  2015-02-10 22:56:29      5477   \n",
              "2        3.0  2015-01-22 20:39:28  2015-01-22 21:09:09      5477   \n",
              "3        3.0  2015-02-03 21:21:45  2015-02-03 22:13:00      5477   \n",
              "4        3.0  2015-02-15 02:40:36  2015-02-15 03:20:26      5477   \n",
              "\n",
              "  store_primary_category  order_protocol  total_items  subtotal  \\\n",
              "0               american             1.0            4      3441   \n",
              "1                mexican             2.0            1      1900   \n",
              "2                    NaN             1.0            1      1900   \n",
              "3                    NaN             1.0            6      6900   \n",
              "4                    NaN             1.0            3      3900   \n",
              "\n",
              "   num_distinct_items  min_item_price  max_item_price  total_onshift  \\\n",
              "0                   4             557            1239           33.0   \n",
              "1                   1            1400            1400            1.0   \n",
              "2                   1            1900            1900            1.0   \n",
              "3                   5             600            1800            1.0   \n",
              "4                   3            1100            1600            6.0   \n",
              "\n",
              "   total_busy  total_outstanding_orders  estimated_order_place_duration  \\\n",
              "0        14.0                      21.0                             446   \n",
              "1         2.0                       2.0                             446   \n",
              "2         0.0                       0.0                             446   \n",
              "3         1.0                       2.0                             446   \n",
              "4         6.0                       9.0                             446   \n",
              "\n",
              "   estimated_store_to_consumer_driving_duration  \n",
              "0                                         861.0  \n",
              "1                                         690.0  \n",
              "2                                         690.0  \n",
              "3                                         289.0  \n",
              "4                                         650.0  "
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "ROOT_DIR = '/content/'\n",
        "DATA_PATH = os.path.join(ROOT_DIR, 'delivery_raw.csv')\n",
        "delivery = pd.read_csv(DATA_PATH, sep='\\t')\n",
        "\n",
        "delivery.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTAnk6YRdbFX"
      },
      "source": [
        "## Data Cleaning & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpjrczADdeTs"
      },
      "source": [
        "- Null value handling\n",
        "  - `actual_delivery_time` : null 값 제거 및 레이블링에 사용 후 drop\n",
        "  - `market_id` : mode\n",
        "  - `order_protocol` : mode\n",
        "  - `store_primary_category` : other \n",
        "  - `total_onshift` : mean\n",
        "  - `total_busy` : mean\n",
        "  - `total_outstanding_orders` : mean\n",
        "  - `estimated_store_to_consumer_driving_duration`: mean\n",
        "- Cleaning\n",
        "  - 제거\n",
        "    - `label` : >= 60000 제거\n",
        "    - `total_items` : >= 400 제거\n",
        "    - `max_item_price` >= 10000 제거\n",
        "  - 변경\n",
        "    - `total_outstanding_orders` : < 0 -> 0\n",
        "    - `min_item_price` : < 0 -> 0\n",
        "    - `total_outstanding_orders` : < 0 -> 0\n",
        "- Extra Column\n",
        "  - `onshift` = `total_onshift` - `total_busy` 값 중 음의 값을 0으로 만들어 학습에 사용\n",
        "  - `created_at` : 시간대를 범주형 데이터 (19 ~ 1], (1 ~ 5] (5 ~ 19]\n",
        "\n",
        "- Numeric Columns\n",
        "  - `total_items`\n",
        "  - `subtotal`\n",
        "  - `num_distint_item`\n",
        "  - `min_item_price`\n",
        "  - `max_item_price`\n",
        "  - `total_outstanding_orders`\n",
        "  - `estimated_store_to_consumer_driving_duration`\n",
        "  - `onshift`\n",
        "- Category Columns\n",
        "    - One-hot\n",
        "        - `created_at`\n",
        "    - Ordinal\n",
        "        - `market_id`\n",
        "        - `order_protocol`\n",
        "        - `store_primary_category`\n",
        "- **DROP COLUMNS**\n",
        "  - `total_onshift`, `total_busy`, `store_id`, `actual_delivery_time`, `estimated_order_place_duration`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "5PiG1pyEde4q"
      },
      "outputs": [],
      "source": [
        "def cleaning(data, labeling=True):\n",
        "    if labeling:\n",
        "        # 레이블링\n",
        "        data = data.drop(data.index[data['actual_delivery_time'].isnull()], axis=0)\n",
        "        data['created_at'] = pd.to_datetime(data['created_at'])\n",
        "        data['actual_delivery_time'] = pd.to_datetime(data['actual_delivery_time'])\n",
        "        data['label'] = (pd.DatetimeIndex(data['actual_delivery_time']) - pd.DatetimeIndex(data['created_at'])).total_seconds()\n",
        "\n",
        "    # cleaning\n",
        "    ## 최빈값으로 채우기\n",
        "    data['market_id'].fillna(float(data['market_id'].mode()), inplace=True)\n",
        "    data['order_protocol'].fillna(float(data['order_protocol'].mode()), inplace=True)\n",
        "    ## 평균으로 채우기\n",
        "    data['total_outstanding_orders'].fillna(float(data['total_outstanding_orders'].mean()), inplace=True)\n",
        "    data['total_onshift'].fillna(float(data['total_onshift'].mean()), inplace=True)\n",
        "    data['total_busy'].fillna(float(data['total_busy'].mean()), inplace=True)\n",
        "    data['estimated_store_to_consumer_driving_duration'].fillna(float(data['estimated_store_to_consumer_driving_duration'].mean()), inplace=True)\n",
        "    ## 특정값으로 채우기\n",
        "    data['store_primary_category'].fillna('other', inplace=True)\n",
        "\n",
        "    ## 이상치 제거\n",
        "    mask = (data['label'] > 60000) | (data['total_items'] >= 400) | (data['max_item_price'] > 10000)\n",
        "    data.drop(data[mask].index, axis=0, inplace=True)\n",
        "    data['min_item_price'][data['min_item_price'] < 0] = 0\n",
        "    data['total_outstanding_orders'][data['total_outstanding_orders'] < 0] = 0\n",
        "    data['onshift'] = data['total_onshift'] - data['total_busy']\n",
        "    data['onshift'][data['onshift'] < 0] = 0\n",
        "    data['onshift'].fillna(float(data['onshift'].mean()), inplace=True)\n",
        "    \n",
        "    ## 시간 범주화 \n",
        "    data['created_at'] = (data['created_at'].dt.hour)\n",
        "    data['created_at'][(data['created_at'] >= 19) | (data['created_at'] < 1)] = 0\n",
        "    data['created_at'][(data['created_at'] >= 1) & (data['created_at'] <= 4)] = 1\n",
        "    data['created_at'][(data['created_at'] >= 5) & (data['created_at'] <= 18)] = 2\n",
        "    \n",
        "    drop_list = ['actual_delivery_time', 'store_id', 'total_onshift', 'total_busy', 'estimated_order_place_duration']\n",
        "    data.drop(drop_list, axis=1, inplace=True)\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "icneUXD-eLNc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "\n",
        "num_attribs = ['total_items', 'subtotal', 'num_distinct_items', \n",
        "               'min_item_price', 'max_item_price', 'total_outstanding_orders', \n",
        "               'estimated_store_to_consumer_driving_duration', 'onshift']\n",
        "one_hot_attribs = ['created_at']\n",
        "ord_attribs = ['market_id', 'order_protocol', 'store_primary_category']\n",
        "\n",
        "num_pipline = Pipeline([\n",
        "    ('std_scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    ('num', num_pipline, num_attribs),\n",
        "    ('one-hot', OneHotEncoder(), one_hot_attribs),\n",
        "    ('ord', OrdinalEncoder(), ord_attribs),\n",
        "], remainder='passthrough')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "XLw1uRAik2dT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TensorData(Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X_data = torch.FloatTensor(X)\n",
        "        self.y_data = torch.FloatTensor(y)\n",
        "    \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "    \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.y_data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg9r211LihMr",
        "outputId": "55b3557d-2e7e-42ba-b149-7628c7a06b23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-55-e832bb2cf94c>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['min_item_price'][data['min_item_price'] < 0] = 0\n",
            "<ipython-input-55-e832bb2cf94c>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['total_outstanding_orders'][data['total_outstanding_orders'] < 0] = 0\n",
            "<ipython-input-55-e832bb2cf94c>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['onshift'][data['onshift'] < 0] = 0\n",
            "<ipython-input-55-e832bb2cf94c>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['created_at'][(data['created_at'] >= 19) | (data['created_at'] < 1)] = 0\n",
            "<ipython-input-55-e832bb2cf94c>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['created_at'][(data['created_at'] >= 1) & (data['created_at'] <= 4)] = 1\n",
            "<ipython-input-55-e832bb2cf94c>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['created_at'][(data['created_at'] >= 5) & (data['created_at'] <= 18)] = 2\n"
          ]
        }
      ],
      "source": [
        "cleaned_delivery = cleaning(delivery)\n",
        "\n",
        "# split train test set [0.9, 0.1]\n",
        "train_data, test_data = train_test_split(cleaned_delivery, test_size=0.1)\n",
        "\n",
        "X_train = train_data.drop(['label'], axis=1)\n",
        "y_train = train_data['label'].to_numpy().reshape((-1, 1))\n",
        "X_test = test_data.drop(['label'], axis=1)\n",
        "y_test = test_data['label'].to_numpy().reshape((-1, 1))\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
        "\n",
        "X_train = full_pipeline.fit_transform(X_train)\n",
        "X_test = full_pipeline.fit_transform(X_test)\n",
        "\n",
        "train_set = TensorData(X_train, y_train)\n",
        "test_set = TensorData(X_test, y_test)\n",
        "\n",
        "# train_dataloader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS4fhLaQmtL6"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "xZLZADzOn8Q8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "zXzqHrzQn15r"
      },
      "outputs": [],
      "source": [
        "class Regressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim):\n",
        "        super(Regressor, self).__init__()\n",
        "        self.reg = nn.Sequential(\n",
        "            nn.Linear(input_dim, 24, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, 12, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12, 6, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6, 1)            \n",
        "        )\n",
        "    \n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.reg(X)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UnderPredPreventLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(UnderPredPreventLoss, self).__init__()\n",
        "\n",
        "    \n",
        "    def forward(self, output, target):\n",
        "        size = target.size(0)\n",
        "        output = output.view(-1)\n",
        "        target = target.view(-1)\n",
        "        diff = output - target\n",
        "        mask = diff < 0\n",
        "        weight = (mask.float() + 1)\n",
        "\n",
        "        return ((diff * weight)**2).sum() / size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "FaTX1TOJwPYN"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, scheduler=None):\n",
        "    train_loss = 0.\n",
        "    tot_size = 0\n",
        "\n",
        "    model.train()\n",
        "    for data, label in dataloader:\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss\n",
        "        tot_size += label.size(0)\n",
        "        \n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "    train_loss /= tot_size\n",
        "    return train_loss \n",
        "\n",
        "\n",
        "def evaluation(model, dataloader, device):\n",
        "    preds = torch.tensor([], dtype=torch.float)\n",
        "    actual = torch.tensor([], dtype=torch.float)\n",
        "    preds = preds.to(device)\n",
        "    actual = actual.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data, label in dataloader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            \n",
        "            preds = torch.cat((preds, output), dim=0)\n",
        "            actual = torch.cat((actual, label), dim=0)\n",
        "        \n",
        "    preds = preds.cpu().numpy()\n",
        "    actual = actual.cpu().numpy()\n",
        "    rmse = np.sqrt(mean_squared_error(preds, actual))\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "rYoAIlNNOlHL"
      },
      "outputs": [],
      "source": [
        "def full_train(model, epochs, train_loader, val_loader,\n",
        "               criterion, optimizer, scheduler, save_path, device, \n",
        "               max_patience=5):\n",
        "    min_val_rmse = float('inf')\n",
        "    patience = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_one_epoch(model, train_loader, criterion, optimizer, device, scheduler)\n",
        "        train_rmse = evaluation(model, train_loader, device)\n",
        "        val_rmse = evaluation(model, val_loader, device)\n",
        "        print(f\"Epoch: {epoch + 1:03d} Train Loss: {train_rmse:0.4f} Val Loss: {val_rmse:0.4f}\")  \n",
        "        \n",
        "        if min_val_rmse > val_rmse:\n",
        "            print(\"Detected New Best Model\")\n",
        "            torch.save(model, save_path)\n",
        "            patience = 0\n",
        "            min_val_rmse = val_rmse\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience > max_patience:\n",
        "                print(\"Early Stopping\")\n",
        "                return\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "L4ompDNoQiG3"
      },
      "outputs": [],
      "source": [
        "def val_cross_train(dataset, epoch, device, save_path):\n",
        "    validation_loss = []\n",
        "    min_val_rmse = float('inf')\n",
        "\n",
        "    kfold = KFold(n_splits=10, shuffle=True)\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "        train_dataloader = DataLoader(dataset, batch_size=128, sampler=train_subsampler)\n",
        "        val_dataloader = DataLoader(dataset, batch_size=128, sampler=val_subsampler)\n",
        "\n",
        "        model = Regressor(14)\n",
        "        model.to(device)\n",
        "        criterion = UnderPredPreventLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
        "\n",
        "        for _ in range(epoch):\n",
        "            cur_loss = train_one_epoch(model, train_dataloader, criterion, optimizer, device, scheduler)\n",
        "            print(f\"Epoch { _ + 1:03d} Loss: {cur_loss:0.4f}\")\n",
        "\n",
        "        train_rmse = evaluation(model, train_dataloader, device)\n",
        "        val_rmse = evaluation(model, val_dataloader, device)\n",
        "        print(f\"K-fold: {fold:03d} Train Loss: {train_rmse:0.4f} Val Loss: {val_rmse:0.4f}\")  \n",
        "        validation_loss.append(val_rmse)\n",
        "\n",
        "        if min_val_rmse > val_rmse:\n",
        "            min_val_rmse = val_rmse\n",
        "            print(\"Detected New Best Model Save ...\")\n",
        "            torch.save(model, save_path)\n",
        "        \n",
        "    validation_loss = np.array(validation_loss)\n",
        "    mean = np.mean(validation_loss)\n",
        "    std = np.std(validation_loss)\n",
        "    print(f\"Validation Score: {mean:04f} , {std:0.4f}\")\n",
        "    return validation_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv3EUf6UMpGa",
        "outputId": "f3c91031-59fb-42e7-ce5d-29985aac8abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 Loss: 25367.5020\n",
            "Epoch 002 Loss: 8993.7207\n",
            "Epoch 003 Loss: 6457.7368\n",
            "Epoch 004 Loss: 5982.7700\n",
            "Epoch 005 Loss: 5934.2158\n",
            "Epoch 006 Loss: 5912.3232\n",
            "Epoch 007 Loss: 5893.2559\n",
            "Epoch 008 Loss: 5880.7881\n",
            "Epoch 009 Loss: 5866.8579\n",
            "Epoch 010 Loss: 5865.7598\n",
            "Epoch 011 Loss: 5853.6094\n",
            "Epoch 012 Loss: 5852.0737\n",
            "Epoch 013 Loss: 5846.8159\n",
            "Epoch 014 Loss: 5842.2212\n",
            "Epoch 015 Loss: 5837.2285\n",
            "K-fold: 000 Train Loss: 1178.3875 Val Loss: 1142.9750\n",
            "Detected New Best Model Save ...\n",
            "Epoch 001 Loss: 24587.2930\n",
            "Epoch 002 Loss: 8482.4209\n",
            "Epoch 003 Loss: 6014.3320\n",
            "Epoch 004 Loss: 5730.3213\n",
            "Epoch 005 Loss: 5707.9570\n",
            "Epoch 006 Loss: 5687.3555\n",
            "Epoch 007 Loss: 5679.6323\n",
            "Epoch 008 Loss: 5667.1807\n",
            "Epoch 009 Loss: 5657.5898\n",
            "Epoch 010 Loss: 5654.1987\n",
            "Epoch 011 Loss: 5649.8096\n",
            "Epoch 012 Loss: 5648.3076\n",
            "Epoch 013 Loss: 5643.9204\n",
            "Epoch 014 Loss: 5647.3481\n",
            "Epoch 015 Loss: 5643.2847\n",
            "K-fold: 001 Train Loss: 1228.1510 Val Loss: 1290.7897\n",
            "Epoch 001 Loss: 24606.9590\n",
            "Epoch 002 Loss: 8559.1465\n",
            "Epoch 003 Loss: 6224.5791\n",
            "Epoch 004 Loss: 5979.1436\n",
            "Epoch 005 Loss: 5950.2744\n",
            "Epoch 006 Loss: 5928.4585\n",
            "Epoch 007 Loss: 5912.0708\n",
            "Epoch 008 Loss: 5900.4609\n",
            "Epoch 009 Loss: 5890.2476\n",
            "Epoch 010 Loss: 5883.4702\n",
            "Epoch 011 Loss: 5878.4375\n",
            "Epoch 012 Loss: 5869.0947\n",
            "Epoch 013 Loss: 5865.7686\n",
            "Epoch 014 Loss: 5860.5767\n",
            "Epoch 015 Loss: 5888.4946\n",
            "K-fold: 002 Train Loss: 1215.2800 Val Loss: 1156.0066\n",
            "Epoch 001 Loss: 25838.2441\n",
            "Epoch 002 Loss: 9185.4971\n",
            "Epoch 003 Loss: 6470.4741\n",
            "Epoch 004 Loss: 5835.0547\n",
            "Epoch 005 Loss: 5798.1123\n",
            "Epoch 006 Loss: 5779.3032\n",
            "Epoch 007 Loss: 5765.5532\n",
            "Epoch 008 Loss: 5757.4883\n",
            "Epoch 009 Loss: 5744.4937\n",
            "Epoch 010 Loss: 5739.0791\n",
            "Epoch 011 Loss: 5732.2158\n",
            "Epoch 012 Loss: 5728.6880\n",
            "Epoch 013 Loss: 5724.8018\n",
            "Epoch 014 Loss: 5721.8115\n",
            "Epoch 015 Loss: 5725.2979\n",
            "K-fold: 003 Train Loss: 1204.0659 Val Loss: 1230.7234\n",
            "Epoch 001 Loss: 24414.9004\n",
            "Epoch 002 Loss: 8546.7988\n",
            "Epoch 003 Loss: 6266.6797\n",
            "Epoch 004 Loss: 5918.0649\n",
            "Epoch 005 Loss: 5881.1499\n",
            "Epoch 006 Loss: 5856.3315\n",
            "Epoch 007 Loss: 5838.8481\n",
            "Epoch 008 Loss: 5824.2935\n",
            "Epoch 009 Loss: 5811.3892\n",
            "Epoch 010 Loss: 5805.5444\n",
            "Epoch 011 Loss: 5791.9443\n",
            "Epoch 012 Loss: 5790.3091\n",
            "Epoch 013 Loss: 5785.6001\n",
            "Epoch 014 Loss: 5780.5830\n",
            "Epoch 015 Loss: 5777.0137\n",
            "K-fold: 004 Train Loss: 1174.9321 Val Loss: 1167.5923\n",
            "Epoch 001 Loss: 24219.3105\n",
            "Epoch 002 Loss: 8748.1992\n",
            "Epoch 003 Loss: 6237.1802\n",
            "Epoch 004 Loss: 5926.0601\n",
            "Epoch 005 Loss: 5904.1743\n",
            "Epoch 006 Loss: 5890.2822\n",
            "Epoch 007 Loss: 5876.2305\n",
            "Epoch 008 Loss: 5860.9644\n",
            "Epoch 009 Loss: 5851.2939\n",
            "Epoch 010 Loss: 5844.5122\n",
            "Epoch 011 Loss: 5837.3076\n",
            "Epoch 012 Loss: 5832.6494\n",
            "Epoch 013 Loss: 5826.3369\n",
            "Epoch 014 Loss: 5822.9648\n",
            "Epoch 015 Loss: 5818.2671\n",
            "K-fold: 005 Train Loss: 1190.0325 Val Loss: 1163.1328\n",
            "Epoch 001 Loss: 25498.3613\n",
            "Epoch 002 Loss: 9399.0703\n",
            "Epoch 003 Loss: 6553.8965\n",
            "Epoch 004 Loss: 5886.2866\n",
            "Epoch 005 Loss: 5830.7422\n",
            "Epoch 006 Loss: 5810.5801\n",
            "Epoch 007 Loss: 5795.8052\n",
            "Epoch 008 Loss: 5776.8315\n",
            "Epoch 009 Loss: 5760.3047\n",
            "Epoch 010 Loss: 5756.7471\n",
            "Epoch 011 Loss: 5730.4961\n",
            "Epoch 012 Loss: 5713.6338\n",
            "Epoch 013 Loss: 5716.2241\n",
            "Epoch 014 Loss: 5696.7583\n",
            "Epoch 015 Loss: 5695.4751\n",
            "K-fold: 006 Train Loss: 1185.1147 Val Loss: 1220.5138\n",
            "Epoch 001 Loss: 24965.1523\n",
            "Epoch 002 Loss: 8932.2725\n",
            "Epoch 003 Loss: 6339.1606\n",
            "Epoch 004 Loss: 5948.1514\n",
            "Epoch 005 Loss: 5917.8525\n",
            "Epoch 006 Loss: 5899.6411\n",
            "Epoch 007 Loss: 5886.4023\n",
            "Epoch 008 Loss: 5867.7983\n",
            "Epoch 009 Loss: 5856.2886\n",
            "Epoch 010 Loss: 5847.1982\n",
            "Epoch 011 Loss: 5839.7246\n",
            "Epoch 012 Loss: 5831.4839\n",
            "Epoch 013 Loss: 5828.6631\n",
            "Epoch 014 Loss: 5816.7383\n",
            "Epoch 015 Loss: 5820.1753\n",
            "K-fold: 007 Train Loss: 1191.9418 Val Loss: 1158.3552\n",
            "Epoch 001 Loss: 27144.6387\n",
            "Epoch 002 Loss: 9928.3408\n",
            "Epoch 003 Loss: 6912.9038\n",
            "Epoch 004 Loss: 5896.0435\n",
            "Epoch 005 Loss: 5834.3926\n",
            "Epoch 006 Loss: 5819.9399\n",
            "Epoch 007 Loss: 5800.0698\n",
            "Epoch 008 Loss: 5789.8838\n",
            "Epoch 009 Loss: 5774.6416\n",
            "Epoch 010 Loss: 5762.1724\n",
            "Epoch 011 Loss: 5749.7222\n",
            "Epoch 012 Loss: 5745.5576\n",
            "Epoch 013 Loss: 5735.5762\n",
            "Epoch 014 Loss: 5728.5928\n",
            "Epoch 015 Loss: 5721.4795\n",
            "K-fold: 008 Train Loss: 1200.0254 Val Loss: 1228.0304\n",
            "Epoch 001 Loss: 26637.2090\n",
            "Epoch 002 Loss: 9278.4590\n",
            "Epoch 003 Loss: 6708.9175\n",
            "Epoch 004 Loss: 5936.4639\n",
            "Epoch 005 Loss: 5863.5977\n",
            "Epoch 006 Loss: 5842.7480\n",
            "Epoch 007 Loss: 5826.2266\n",
            "Epoch 008 Loss: 5814.3413\n",
            "Epoch 009 Loss: 5801.5527\n",
            "Epoch 010 Loss: 5793.3550\n",
            "Epoch 011 Loss: 5787.8564\n",
            "Epoch 012 Loss: 5779.4253\n",
            "Epoch 013 Loss: 5772.5259\n",
            "Epoch 014 Loss: 5770.8101\n",
            "Epoch 015 Loss: 5764.5342\n",
            "K-fold: 009 Train Loss: 1191.9192 Val Loss: 1199.4203\n",
            "Validation Score: 1195.753906 , 44.2089\n"
          ]
        }
      ],
      "source": [
        "val_cross_train(train_set, 15, device, './val_cross_best_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhCn9ZxbWl2b",
        "outputId": "0c689a54-5221-40be-f71e-438943a68be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST SET RMSE : 1167.2243, Under Predict Rate: 0.233\n"
          ]
        }
      ],
      "source": [
        "final_preds = predict(test_dataloader, './val_cross_best_1.h5')\n",
        "\n",
        "final_rmse = np.sqrt(mean_squared_error(y_test.reshape(-1), final_preds))\n",
        "under_pred_rate = ((final_preds - y_test.reshape(-1)) < 0).sum() / y_test.shape[0]\n",
        "\n",
        "print(f\"TEST SET RMSE : {final_rmse:0.4f}, Under Predict Rate: {under_pred_rate:0.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
