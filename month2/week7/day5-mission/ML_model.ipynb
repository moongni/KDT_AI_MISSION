{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>actual_delivery_time</th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_primary_category</th>\n",
       "      <th>order_protocol</th>\n",
       "      <th>total_items</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>num_distinct_items</th>\n",
       "      <th>min_item_price</th>\n",
       "      <th>max_item_price</th>\n",
       "      <th>total_onshift</th>\n",
       "      <th>total_busy</th>\n",
       "      <th>total_outstanding_orders</th>\n",
       "      <th>estimated_order_place_duration</th>\n",
       "      <th>estimated_store_to_consumer_driving_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-02-06 22:24:17</td>\n",
       "      <td>2015-02-06 23:27:16</td>\n",
       "      <td>1845</td>\n",
       "      <td>american</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3441</td>\n",
       "      <td>4</td>\n",
       "      <td>557</td>\n",
       "      <td>1239</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>446</td>\n",
       "      <td>861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-02-10 21:49:25</td>\n",
       "      <td>2015-02-10 22:56:29</td>\n",
       "      <td>5477</td>\n",
       "      <td>mexican</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>446</td>\n",
       "      <td>690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-01-22 20:39:28</td>\n",
       "      <td>2015-01-22 21:09:09</td>\n",
       "      <td>5477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>446</td>\n",
       "      <td>690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-02-03 21:21:45</td>\n",
       "      <td>2015-02-03 22:13:00</td>\n",
       "      <td>5477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6900</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>446</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-02-15 02:40:36</td>\n",
       "      <td>2015-02-15 03:20:26</td>\n",
       "      <td>5477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3900</td>\n",
       "      <td>3</td>\n",
       "      <td>1100</td>\n",
       "      <td>1600</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>446</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   market_id           created_at actual_delivery_time  store_id  \\\n",
       "0        1.0  2015-02-06 22:24:17  2015-02-06 23:27:16      1845   \n",
       "1        2.0  2015-02-10 21:49:25  2015-02-10 22:56:29      5477   \n",
       "2        3.0  2015-01-22 20:39:28  2015-01-22 21:09:09      5477   \n",
       "3        3.0  2015-02-03 21:21:45  2015-02-03 22:13:00      5477   \n",
       "4        3.0  2015-02-15 02:40:36  2015-02-15 03:20:26      5477   \n",
       "\n",
       "  store_primary_category  order_protocol  total_items  subtotal  \\\n",
       "0               american             1.0            4      3441   \n",
       "1                mexican             2.0            1      1900   \n",
       "2                    NaN             1.0            1      1900   \n",
       "3                    NaN             1.0            6      6900   \n",
       "4                    NaN             1.0            3      3900   \n",
       "\n",
       "   num_distinct_items  min_item_price  max_item_price  total_onshift  \\\n",
       "0                   4             557            1239           33.0   \n",
       "1                   1            1400            1400            1.0   \n",
       "2                   1            1900            1900            1.0   \n",
       "3                   5             600            1800            1.0   \n",
       "4                   3            1100            1600            6.0   \n",
       "\n",
       "   total_busy  total_outstanding_orders  estimated_order_place_duration  \\\n",
       "0        14.0                      21.0                             446   \n",
       "1         2.0                       2.0                             446   \n",
       "2         0.0                       0.0                             446   \n",
       "3         1.0                       2.0                             446   \n",
       "4         6.0                       9.0                             446   \n",
       "\n",
       "   estimated_store_to_consumer_driving_duration  \n",
       "0                                         861.0  \n",
       "1                                         690.0  \n",
       "2                                         690.0  \n",
       "3                                         289.0  \n",
       "4                                         650.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = '.'\n",
    "DATA_PATH = os.path.join(ROOT_DIR, 'data', 'delivery_raw.csv')\n",
    "\n",
    "delivery = pd.read_csv(DATA_PATH, sep='\\t')\n",
    "\n",
    "delivery.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preprocessing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Null value handling\n",
    "  - `actual_delivery_time` : null 값 제거 및 레이블링에 사용 후 drop\n",
    "  - `market_id` : mode\n",
    "  - `order_protocol` : mode\n",
    "  - `store_primary_category` : other \n",
    "  - `total_onshift` : mean\n",
    "  - `total_busy` : mean\n",
    "  - `total_outstanding_orders` : mean\n",
    "  - `estimated_store_to_consumer_driving_duration`: mean\n",
    "- Cleaning\n",
    "  - 제거\n",
    "    - `label` : >= 60000 제거\n",
    "    - `total_items` : >= 400 제거\n",
    "    - `max_item_price` >= 10000 제거\n",
    "  - 변경\n",
    "    - `total_outstanding_orders` : < 0 -> 0\n",
    "    - `min_item_price` : < 0 -> 0\n",
    "    - `total_outstanding_orders` : < 0 -> 0\n",
    "- Extra Column\n",
    "  - `onshift` = `total_onshift` - `total_busy` 값 중 음의 값을 0으로 만들어 학습에 사용\n",
    "  - `created_at` : 시간대를 범주형 데이터 (19 ~ 1], (1 ~ 5] (5 ~ 19]\n",
    "\n",
    "- Numeric Columns\n",
    "  - `total_items`\n",
    "  - `subtotal`\n",
    "  - `num_distint_item`\n",
    "  - `min_item_price`\n",
    "  - `max_item_price`\n",
    "  - `total_outstanding_orders`\n",
    "  - `estimated_store_to_consumer_driving_duration`\n",
    "  - `onshift`\n",
    "- Category Columns\n",
    "  - `market_id`\n",
    "  - `order_protocol`\n",
    "  - `created_at` : one-hot encoding\n",
    "  - `store_primary_category` : ordinal encoding\n",
    "  - \n",
    "- **DROP COLUMNS**\n",
    "  - `total_onshift`, `total_busy`, `store_id`, `actual_delivery_time`, **`estimated_order_place_duration`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    # 레이블링\n",
    "    data = data.drop(data.index[data['actual_delivery_time'].isnull()], axis=0)\n",
    "    data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "    data['actual_delivery_time'] = pd.to_datetime(data['actual_delivery_time'])\n",
    "    data['label'] = (pd.DatetimeIndex(data['actual_delivery_time']) - pd.DatetimeIndex(data['created_at'])).total_seconds()\n",
    "\n",
    "    # cleaning\n",
    "    ## 최빈값으로 채우기\n",
    "    data['market_id'].fillna(float(data['market_id'].mode()), inplace=True)\n",
    "    data['order_protocol'].fillna(float(data['order_protocol'].mode()), inplace=True)\n",
    "    ## 평균으로 채우기\n",
    "    data['total_outstanding_orders'].fillna(float(data['total_outstanding_orders'].mean()), inplace=True)\n",
    "    data['total_onshift'].fillna(float(data['total_onshift'].mean()), inplace=True)\n",
    "    data['total_busy'].fillna(float(data['total_busy'].mean()), inplace=True)\n",
    "    data['estimated_store_to_consumer_driving_duration'].fillna(float(data['estimated_store_to_consumer_driving_duration'].mean()), inplace=True)\n",
    "    ## 특정값으로 채우기\n",
    "    data['store_primary_category'].fillna('other', inplace=True)\n",
    "\n",
    "    ## 이상치 제거\n",
    "    mask = (data['label'] > 60000) | (data['total_items'] >= 400) | (data['max_item_price'] > 10000)\n",
    "    data.drop(data[mask].index, axis=0, inplace=True)\n",
    "    data['min_item_price'][data['min_item_price'] < 0] = 0\n",
    "    data['total_outstanding_orders'][data['total_outstanding_orders'] < 0] = 0\n",
    "    data['onshift'] = data['total_onshift'] - data['total_busy']\n",
    "    data['onshift'][data['onshift'] < 0] = 0\n",
    "    data['onshift'].fillna(float(data['onshift'].mean()), inplace=True)\n",
    "    \n",
    "    ## 시간 범주화 \n",
    "    data['created_at'] = (data['created_at'].dt.hour)\n",
    "    data['created_at'][(data['created_at'] >= 19) | (data['created_at'] < 1)] = 0\n",
    "    data['created_at'][(data['created_at'] >= 1) & (data['created_at'] <= 4)] = 1\n",
    "    data['created_at'][(data['created_at'] >= 5) & (data['created_at'] <= 18)] = 2\n",
    "    \n",
    "    drop_list = ['actual_delivery_time', 'store_id', 'total_onshift', 'total_busy', 'estimated_order_place_duration']\n",
    "    data.drop(drop_list, axis=1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4675/2457831560.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['min_item_price'][data['min_item_price'] < 0] = 0\n",
      "/tmp/ipykernel_4675/2457831560.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['total_outstanding_orders'][data['total_outstanding_orders'] < 0] = 0\n",
      "/tmp/ipykernel_4675/2457831560.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['onshift'][data['onshift'] < 0] = 0\n",
      "/tmp/ipykernel_4675/2457831560.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'][(data['created_at'] >= 19) | (data['created_at'] < 1)] = 0\n",
      "/tmp/ipykernel_4675/2457831560.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'][(data['created_at'] >= 1) & (data['created_at'] <= 4)] = 1\n",
      "/tmp/ipykernel_4675/2457831560.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'][(data['created_at'] >= 5) & (data['created_at'] <= 18)] = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((177674, 12), (177674,), (19742, 12), (19742,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split train validation set [0.9, 0.1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cleaned_delivery = preprocessing(delivery)\n",
    "\n",
    "train_data, test_data = train_test_split(cleaned_delivery, test_size=0.1)\n",
    "\n",
    "train_label = train_data['label']\n",
    "train_feature = train_data.drop(['label'], axis=1)\n",
    "test_label = test_data['label']\n",
    "test_feature = test_data.drop(['label'], axis=1)\n",
    "\n",
    "train_feature.shape, train_label.shape, test_feature.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "num_attribs = ['total_items', 'subtotal', 'num_distinct_items', \n",
    "               'min_item_price', 'max_item_price', 'total_outstanding_orders', \n",
    "               'estimated_store_to_consumer_driving_duration', 'onshift']\n",
    "one_hot_attribs = ['created_at']\n",
    "ord_attribs = ['store_primary_category']\n",
    "\n",
    "num_pipline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipline, num_attribs),\n",
    "    ('one-hot', OneHotEncoder(), one_hot_attribs),\n",
    "    ('ord', OrdinalEncoder(), ord_attribs),\n",
    "], remainder='passthrough')\n",
    "\n",
    "delivery_prepared = full_pipeline.fit_transform(train_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_score(scores):\n",
    "    print(f\"Mean: {scores.mean()} \\t Std: {scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Mean: 1081.0139592493238 \t Std: 32.532987815255396\n",
      "ElasticNet\n",
      "Mean: 1091.629814542836 \t Std: 32.56719530478251\n",
      "DecisionTreeRegressor\n",
      "Mean: 1559.9843475224595 \t Std: 32.29266179560744\n",
      "GradientBoostingRegressor\n",
      "Mean: 1048.0335287447708 \t Std: 32.67576313825857\n",
      "RandomForestRegressor\n",
      "Mean: 1071.0723168044428 \t Std: 35.67669197114766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.linear_model as lin_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "models = [\n",
    "    {\n",
    "    'name': 'LinearRegression',\n",
    "    'model': lin_model.LinearRegression()\n",
    "    }, {\n",
    "    'name': 'ElasticNet',\n",
    "    'model': lin_model.ElasticNet()\n",
    "    }, {\n",
    "    'name': 'DecisionTreeRegressor',\n",
    "    'model': DecisionTreeRegressor()\n",
    "    }, {\n",
    "    'name': 'GradientBoostingRegressor',\n",
    "    'model': GradientBoostingRegressor()\n",
    "    }, {\n",
    "    'name': 'RandomForestRegressor',\n",
    "    'model': RandomForestRegressor()\n",
    "    },\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model_scores = cross_val_score(model['model'], X_train, y_train,\n",
    "                                   scoring='neg_mean_squared_error', cv=5)\n",
    "    print(model['name'])\n",
    "    display_score(np.sqrt(-model_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTune Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f183c3834c0>,\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f183bc98f40>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f183abd3910>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import random\n",
    "\n",
    "param_distribs = {\n",
    "    'n_estimators': randint(low=50, high=200),\n",
    "    'max_depth': randint(low=1, high=6),\n",
    "    'max_features': randint(low=5, high=14),\n",
    "}\n",
    "grad_reg = GradientBoostingRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(grad_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047.097710879185 {'max_depth': 4, 'max_features': 12, 'n_estimators': 70}\n",
      "1055.8574849205818 {'max_depth': 2, 'max_features': 7, 'n_estimators': 124}\n",
      "1043.9616026620017 {'max_depth': 3, 'max_features': 12, 'n_estimators': 166}\n",
      "1037.94472075293 {'max_depth': 4, 'max_features': 12, 'n_estimators': 180}\n",
      "1037.435502651077 {'max_depth': 5, 'max_features': 6, 'n_estimators': 137}\n",
      "1038.5038317036124 {'max_depth': 4, 'max_features': 10, 'n_estimators': 179}\n",
      "1042.5863357332553 {'max_depth': 4, 'max_features': 9, 'n_estimators': 107}\n",
      "1039.6212690402067 {'max_depth': 5, 'max_features': 13, 'n_estimators': 98}\n",
      "1045.1805886797656 {'max_depth': 3, 'max_features': 7, 'n_estimators': 157}\n",
      "1038.2486462181926 {'max_depth': 4, 'max_features': 13, 'n_estimators': 180}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET RMSE : 1108.9209, Under Predict Rate: 0.423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = rnd_search.best_estimator_\n",
    "\n",
    "final_preds = final_model.predict(X_test)\n",
    "\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_preds))\n",
    "under_pred_rate = ((final_preds - y_test) < 0).sum() / y_test.shape[0]\n",
    "\n",
    "print(f\"TEST SET RMSE : {final_rmse:0.4f}, Under Predict Rate: {under_pred_rate:0.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
